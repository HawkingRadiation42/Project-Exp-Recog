# -*- coding: utf-8 -*-
"""Emotion Recognition 67% test accuracy

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPhsbcPiTHuCTLtPI4P-rBdqfSZqSPTp
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
import cv2
from tensorflow.keras.callbacks import ModelCheckpoint
from pathlib import Path
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.applications.vgg16 import VGG16
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import MaxPool2D, Conv2D, Dropout, BatchNormalization
import os
from tensorflow.keras import Model, layers
from tensorflow.keras.layers import Dropout, Dense, Input, GlobalAveragePooling2D, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#using the unix .glob to find all images(.png files) in our path variable(i.e dataset)
train_path = Path('/content/drive/MyDrive/Emotion Recognition/train')
fil_path = list(train_path.glob(r'**/*.jpg'))

#extracing labels from the file path
label = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], fil_path))

#converting the filefath and labels to dataframes
file_pat = pd.Series(fil_path).astype(str)
train_label = pd.Series(label)

train_df = pd.concat([file_pat, train_label], axis=1)

train_df.columns = ['image', 'label']

train_df.head()

#using the unix .glob to find all images(.png files) in our path variable(i.e dataset)
test_path = Path('/content/drive/MyDrive/Emotion Recognition/test')
file_path = list(test_path.glob(r'**/*.jpg'))

#extracing labels from the file path
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path))

#converting the filefath and labels to dataframes
file_path = pd.Series(file_path).astype(str)
test_label = pd.Series(labels)

test_df = pd.concat([file_path, test_label], axis=1)

test_df.columns = ['image', 'label']

test_df.head()

test_df.shape, train_df.shape

data_df = train_df.append(test_df)

data_df.head()

data_df.shape

train_df['label'].nunique()

from PIL import Image
from numpy import asarray
import tqdm

good_images = []
bad_images = []
for i in tqdm.tqdm(data_df['image']):
  try:
    m = Image.open(i)
    m = np.asarray(m)/255
    good_images.append(m)
  except Exception as e:
    bad_images.append(i)
  continue

bad_images

data_df.shape

for x in bad_images:
  t = data_df.loc[data_df['image'] == x].index
  data_df.drop(t, inplace=True)

data_df.shape

x_train, x_rem = train_test_split(data_df, test_size=0.3, random_state=30)
x_val, x_test = train_test_split(x_rem, test_size=0.5, random_state=30)

train_gen = ImageDataGenerator(rescale=1/255,
                            rotation_range=5,
                            shear_range=0.1,
                            zoom_range=0.1,
                            width_shift_range=0.1,
                            height_shift_range=0.1,
                            horizontal_flip=True,
                            fill_mode='nearest'
                            )


val_gen = ImageDataGenerator(rescale=1/255)

train_df.isna().sum()

train_data = train_gen.flow_from_dataframe(dataframe=x_train, x_col='image', y_col='label', batch_size=128,
                                           target_size=(48, 48), color_mode='rgb', class_mode='categorical', shuffle=True)

val_data = val_gen.flow_from_dataframe(dataframe=x_val, x_col='image', y_col='label', batch_size=128,
                                           target_size=(48, 48), color_mode='rgb', class_mode='categorical', shuffle=True)
test_data = val_gen.flow_from_dataframe(dataframe=x_test, x_col='image', y_col='label', batch_size=128,
                                           target_size=(48, 48), color_mode='rgb', class_mode='categorical', shuffle=True)

"""## Transfer learning"""

vgg = VGG16(input_shape=(48, 48, 3), weights='imagenet', include_top=False)

vgg.summary()

for layer in vgg.layers:
  layer.trainable = True

from keras import Sequential
from keras.layers import Dense,Flatten
np.random.seed(42)
tf.random.set_seed(42)

model = Sequential([
    vgg
])
model.add(Conv2D(512, kernel_size=(1,1), activation='relu'))    
model.add(Conv2D(512, kernel_size=(1,1), activation='relu'))
model.add(Dense(512, activation='relu'))
  
model.add(Flatten())
model.add(Dense(7, activation='softmax'))
model.summary()

learning_rate = 0.0001
optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)
model.compile(optimizer = optimizer, 
              loss = tf.keras.losses.CategoricalCrossentropy(), 
              metrics = ['accuracy'])

checkpoint = ModelCheckpoint('FER.hdf5', monitor= 'val_accuracy', mode= 'max', save_weights_only=True, save_best_only = True, verbose= 1)

history = model.fit(train_data,validation_data = val_data,epochs = 50, callbacks=[checkpoint])

history = history.history
n_epochs = len(history['loss'])

plt.figure(figsize=[14,4])
plt.subplot(1,2,1)
plt.plot(range(1, n_epochs+1), history['loss'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')
plt.legend()
plt.subplot(1,2,2)
plt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')
plt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')
plt.legend()
plt.show()

model.load_weights('/content/FER.hdf5')
model.save('/content/FER.h5')

from keras.models import load_model
RESNET = load_model('/content/FER.h5')
RESNET.evaluate(test_data)

